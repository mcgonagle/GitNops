var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __markAsModule = (target) => __defProp(target, "__esModule", { value: true });
var __export = (target, all) => {
  __markAsModule(target);
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __reExport = (target, module2, desc) => {
  if (module2 && typeof module2 === "object" || typeof module2 === "function") {
    for (let key of __getOwnPropNames(module2))
      if (!__hasOwnProp.call(target, key) && key !== "default")
        __defProp(target, key, { get: () => module2[key], enumerable: !(desc = __getOwnPropDesc(module2, key)) || desc.enumerable });
  }
  return target;
};
var __toModule = (module2) => {
  return __reExport(__markAsModule(__defProp(module2 != null ? __create(__getProtoOf(module2)) : {}, "default", module2 && module2.__esModule && "default" in module2 ? { get: () => module2.default, enumerable: true } : { value: module2, enumerable: true })), module2);
};
var __decorateClass = (decorators, target, key, kind) => {
  var result = kind > 1 ? void 0 : kind ? __getOwnPropDesc(target, key) : target;
  for (var i = decorators.length - 1, decorator; i >= 0; i--)
    if (decorator = decorators[i])
      result = (kind ? decorator(target, key, result) : decorator(result)) || result;
  if (kind && result)
    __defProp(target, key, result);
  return result;
};

// packages/r2/src/index.ts
__export(exports, {
  Checksums: () => Checksums,
  HEX_REGEXP: () => HEX_REGEXP,
  MAX_KEY_SIZE: () => MAX_KEY_SIZE,
  R2Bucket: () => R2Bucket,
  R2MultipartUpload: () => R2MultipartUpload,
  R2Object: () => R2Object,
  R2ObjectBody: () => R2ObjectBody,
  R2Plugin: () => R2Plugin,
  R2_HASH_ALGORITHMS: () => R2_HASH_ALGORITHMS,
  _INTERNAL_PREFIX: () => _INTERNAL_PREFIX,
  _valueToArray: () => _valueToArray,
  createMD5Hash: () => createMD5Hash,
  createMultipartUpload: () => createMultipartUpload,
  createVersion: () => createVersion,
  deleteMultipartParts: () => deleteMultipartParts,
  getMultipartValue: () => getMultipartValue,
  parseHttpMetadata: () => parseHttpMetadata,
  parseOnlyIf: () => parseOnlyIf,
  parseR2ObjectMetadata: () => parseR2ObjectMetadata,
  testR2Conditional: () => testR2Conditional,
  validateMultipartKey: () => validateMultipartKey
});

// packages/r2/src/bucket.ts
var import_buffer2 = __toModule(require("buffer"));
var import_crypto3 = __toModule(require("crypto"));
var import_consumers3 = __toModule(require("stream/consumers"));
var import_web3 = __toModule(require("stream/web"));
var import_util2 = __toModule(require("util"));
var import_core3 = __toModule(require("@miniflare/core"));
var import_shared3 = __toModule(require("@miniflare/shared"));
var import_undici2 = __toModule(require("undici"));

// packages/r2/src/multipart.ts
var import_assert2 = __toModule(require("assert"));
var import_buffer = __toModule(require("buffer"));
var import_crypto2 = __toModule(require("crypto"));
var import_consumers2 = __toModule(require("stream/consumers"));
var import_web2 = __toModule(require("stream/web"));
var import_util = __toModule(require("util"));
var import_core2 = __toModule(require("@miniflare/core"));
var import_shared2 = __toModule(require("@miniflare/shared"));

// packages/r2/src/r2Object.ts
var import_assert = __toModule(require("assert"));
var import_crypto = __toModule(require("crypto"));
var import_consumers = __toModule(require("stream/consumers"));
var import_web = __toModule(require("stream/web"));
var import_core = __toModule(require("@miniflare/core"));
var import_shared = __toModule(require("@miniflare/shared"));
var import_undici = __toModule(require("undici"));
var MAX_KEY_SIZE = 1024;
var HEX_REGEXP = /^[A-Fa-f0-9]*$/;
var R2_HASH_ALGORITHMS = [
  { name: "MD5", field: "md5", expectedBytes: 16 },
  { name: "SHA-1", field: "sha1", expectedBytes: 20 },
  { name: "SHA-256", field: "sha256", expectedBytes: 32 },
  { name: "SHA-384", field: "sha384", expectedBytes: 48 },
  { name: "SHA-512", field: "sha512", expectedBytes: 64 }
];
function maybeHexDecode(hex) {
  return hex === void 0 ? void 0 : (0, import_shared.viewToBuffer)(Buffer.from(hex, "hex"));
}
var Checksums = class {
  #checksums;
  constructor(checksums) {
    this.#checksums = checksums;
  }
  get md5() {
    return maybeHexDecode(this.#checksums.md5);
  }
  get sha1() {
    return maybeHexDecode(this.#checksums.sha1);
  }
  get sha256() {
    return maybeHexDecode(this.#checksums.sha256);
  }
  get sha384() {
    return maybeHexDecode(this.#checksums.sha384);
  }
  get sha512() {
    return maybeHexDecode(this.#checksums.sha512);
  }
  toJSON() {
    return this.#checksums;
  }
};
function createMD5Hash(input) {
  return import_crypto.default.createHash("md5").update(input).digest("hex");
}
function createVersion() {
  const size = 32;
  return import_crypto.default.randomBytes(size).toString("base64").slice(0, size);
}
function parseR2ObjectMetadata(meta) {
  meta.uploaded = new Date(meta.uploaded);
  if (meta.httpMetadata.cacheExpiry) {
    meta.httpMetadata.cacheExpiry = new Date(meta.httpMetadata.cacheExpiry);
  }
}
function parseHttpMetadata(httpMetadata) {
  if (httpMetadata === void 0)
    return {};
  if (httpMetadata instanceof import_undici.Headers) {
    const cExpiry = httpMetadata.get("cache-expiry");
    return {
      contentType: httpMetadata.get("content-type") ?? void 0,
      contentLanguage: httpMetadata.get("content-language") ?? void 0,
      contentDisposition: httpMetadata.get("content-disposition") ?? void 0,
      contentEncoding: httpMetadata.get("content-encoding") ?? void 0,
      cacheControl: httpMetadata.get("cache-control") ?? void 0,
      cacheExpiry: cExpiry ? new Date(cExpiry) : void 0
    };
  } else {
    httpMetadata = { ...httpMetadata };
    const httpMetadataList = [
      "contentType",
      "contentLanguage",
      "contentDisposition",
      "contentEncoding",
      "cacheControl",
      "cacheExpiry"
    ];
    for (const key of Object.keys(httpMetadata)) {
      if (!httpMetadataList.includes(key)) {
        delete httpMetadata[key];
      }
    }
    return httpMetadata;
  }
}
function testR2Conditional(conditional, metadata) {
  const { etagMatches, etagDoesNotMatch, uploadedBefore, uploadedAfter } = conditional;
  if (metadata === void 0) {
    return etagMatches === void 0 && uploadedAfter === void 0;
  }
  const { etag, uploaded } = metadata;
  const ifMatch = etagMatches ? matchStrings(etagMatches, etag) : null;
  if (ifMatch === false)
    return false;
  const ifNoneMatch = etagDoesNotMatch ? !matchStrings(etagDoesNotMatch, etag) : null;
  if (ifNoneMatch === false)
    return false;
  if (ifMatch !== true && uploadedBefore !== void 0 && uploaded > uploadedBefore) {
    return false;
  }
  if (ifNoneMatch !== true && uploadedAfter !== void 0 && uploaded < uploadedAfter) {
    return false;
  }
  return true;
}
function matchStrings(a, b) {
  if (typeof a === "string")
    return a === b;
  else
    return a.includes(b);
}
function parseHeaderArray(input) {
  if (!input.includes(","))
    return stripQuotes(input);
  return input.split(",").map((x) => stripQuotes(x));
}
function stripQuotes(input) {
  input = input.trim();
  if (input[0] === '"')
    input = input.slice(1);
  if (input[input.length - 1] === '"')
    input = input.slice(0, -1);
  return input;
}
function parseOnlyIf(onlyIf) {
  if (onlyIf === void 0)
    return {};
  if (onlyIf instanceof import_undici.Headers) {
    onlyIf = {
      etagMatches: onlyIf.get("if-match") ?? void 0,
      etagDoesNotMatch: onlyIf.get("if-none-match") ?? void 0,
      uploadedBefore: onlyIf.get("if-unmodified-since") ?? void 0,
      uploadedAfter: onlyIf.get("if-modified-since") ?? void 0
    };
  }
  if (typeof onlyIf.etagMatches === "string") {
    onlyIf.etagMatches = parseHeaderArray(onlyIf.etagMatches);
  } else if (Array.isArray(onlyIf.etagMatches)) {
    onlyIf.etagMatches = onlyIf.etagMatches.map((x) => stripQuotes(x));
  }
  if (typeof onlyIf.etagDoesNotMatch === "string") {
    onlyIf.etagDoesNotMatch = parseHeaderArray(onlyIf.etagDoesNotMatch);
  } else if (Array.isArray(onlyIf.etagDoesNotMatch)) {
    onlyIf.etagDoesNotMatch = onlyIf.etagDoesNotMatch.map((x) => stripQuotes(x));
  }
  if (typeof onlyIf.uploadedBefore === "string") {
    onlyIf.uploadedBefore = new Date(stripQuotes(onlyIf.uploadedBefore));
  }
  if (typeof onlyIf.uploadedAfter === "string") {
    onlyIf.uploadedAfter = new Date(stripQuotes(onlyIf.uploadedAfter));
  }
  return onlyIf;
}
var R2Object = class {
  key;
  version;
  size;
  etag;
  httpEtag;
  uploaded;
  httpMetadata;
  customMetadata;
  range;
  #checksums;
  constructor(metadata) {
    this.key = metadata.key;
    this.version = metadata.version;
    this.size = metadata.size;
    this.etag = metadata.etag;
    this.httpEtag = metadata.httpEtag;
    this.uploaded = metadata.uploaded;
    this.httpMetadata = metadata.httpMetadata;
    this.customMetadata = metadata.customMetadata;
    this.range = metadata.range;
    const checksums = { ...metadata.checksums };
    if (metadata.multipart === void 0) {
      (0, import_assert.default)(metadata.etag.length === 32 && HEX_REGEXP.test(metadata.etag), "Expected `etag` to be an MD5 hash");
      checksums.md5 = metadata.etag;
    }
    this.#checksums = new Checksums(checksums);
  }
  get checksums() {
    return this.#checksums;
  }
  writeHttpMetadata(headers) {
    for (const [key, value] of Object.entries(this.httpMetadata)) {
      const camelToDash = key.replace(/([A-Z])/g, "-$1").toLowerCase();
      headers.set(camelToDash, value);
    }
  }
};
var R2ObjectBody = class extends R2Object {
  body;
  constructor(metadata, value) {
    super(metadata);
    if (value instanceof import_web.ReadableStream) {
      this.body = value;
      return;
    }
    this.body = new import_web.ReadableStream({
      type: "bytes",
      async pull(controller) {
        await (0, import_shared.waitForOpenInputGate)();
        if (value.byteLength)
          controller.enqueue(value);
        controller.close();
        controller.byobRequest?.respond(0);
      }
    });
  }
  get bodyUsed() {
    return (0, import_core._isDisturbedStream)(this.body);
  }
  async arrayBuffer() {
    if (this.bodyUsed)
      throw new TypeError("Body already used.");
    return import_consumers.default.arrayBuffer(this.body);
  }
  async text() {
    if (this.bodyUsed)
      throw new TypeError("Body already used.");
    return import_consumers.default.text(this.body);
  }
  async json() {
    if (this.bodyUsed)
      throw new TypeError("Body already used.");
    return import_consumers.default.json(this.body);
  }
  async blob() {
    if (this.bodyUsed)
      throw new TypeError("Body already used.");
    return import_consumers.default.blob(this.body);
  }
};

// packages/r2/src/multipart.ts
var _INTERNAL_PREFIX = "__MINIFLARE_INTERNAL__";
var MIN_MULTIPART_UPLOAD_SIZE = 5 * 1024 * 1024;
var encoder = new import_util.TextEncoder();
function validateMultipartKey(method, key) {
  if (Buffer.byteLength(key) > MAX_KEY_SIZE || key.startsWith(_INTERNAL_PREFIX)) {
    throw new TypeError(`${method}: The specified object name is not valid. (10020)`);
  }
}
function validatePartNumber(partNumber) {
  if (partNumber >= 1 && partNumber <= 1e4)
    return;
  throw new TypeError(`Part number must be between 1 and 10000 (inclusive). Actual value was: ${partNumber}`);
}
function generateId(likelyOnFilesystem = false) {
  const size = likelyOnFilesystem && process.platform === "win32" ? 32 : 128;
  return import_crypto2.default.randomBytes(size).toString("base64url");
}
function generateMultipartEtag(md5Hexes) {
  const hash = import_crypto2.default.createHash("md5");
  for (const md5Hex of md5Hexes)
    hash.update(Buffer.from(md5Hex, "hex"));
  return `${hash.digest("hex")}-${md5Hexes.length}`;
}
var INDEX = "index";
function buildKey(key, uploadId, part) {
  return `${_INTERNAL_PREFIX}:multipart:${uploadId}:${key}:${part ?? INDEX}`;
}
function isKnownLengthStream(stream) {
  return (0, import_core2._isBodyStream)(stream) || (0, import_core2._isFixedLengthStream)(stream);
}
async function createMultipartUpload(key, metadata, opts) {
  const uploadId = generateId(true);
  const indexKey = buildKey(key, uploadId);
  await opts.storage.put(indexKey, {
    value: new Uint8Array(),
    metadata
  });
  return new R2MultipartUpload(key, uploadId, opts);
}
function overlaps(a, b) {
  return a.start < b.end && b.start < a.end;
}
function getMultipartValue(storage, key, multipart, range) {
  const queryRange = {
    start: range.offset,
    end: range.offset + range.length
  };
  const parts = [];
  let start = 0;
  for (const part of multipart.parts) {
    const partRange = { start, end: start + part.size };
    if (overlaps(partRange, queryRange)) {
      parts.push({
        partNumber: part.partNumber,
        start: Math.max(partRange.start, queryRange.start) - partRange.start,
        end: Math.min(partRange.end, queryRange.end) - partRange.start
      });
    }
    start = partRange.end;
  }
  return new import_web2.ReadableStream({
    type: "bytes",
    async pull(controller) {
      const part = parts.shift();
      if (part === void 0) {
        await (0, import_shared2.waitForOpenInputGate)();
        controller.close();
        controller.byobRequest?.respond(0);
      } else {
        const partKey = buildKey(key, multipart.uploadId, part.partNumber);
        const value = await storage.getRange(partKey, { offset: part.start, length: part.end - part.start }, true);
        (0, import_assert2.default)(value !== void 0);
        await (0, import_shared2.waitForOpenInputGate)();
        if (value.value.byteLength > 0)
          controller.enqueue(value.value);
      }
    }
  });
}
async function deleteMultipartParts(storage, key, uploadId, excludeKeys) {
  const indexKey = buildKey(key, uploadId);
  const partPrefix = indexKey.substring(0, indexKey.length - INDEX.length);
  const { keys } = await storage.list({ prefix: partPrefix });
  const partKeys = [];
  for (const key2 of keys) {
    if (key2.name !== indexKey && (excludeKeys === void 0 || !excludeKeys.has(key2.name))) {
      partKeys.push(key2.name);
    }
  }
  await storage.deleteMany(partKeys);
}
var R2MultipartUpload = class {
  #storage;
  #blockGlobalAsyncIO;
  #minMultipartUploadSize;
  key;
  uploadId;
  constructor(key, uploadId, opts) {
    this.#storage = opts.storage;
    this.#blockGlobalAsyncIO = opts.blockGlobalAsyncIO ?? false;
    this.#minMultipartUploadSize = opts.minMultipartUploadSize ?? MIN_MULTIPART_UPLOAD_SIZE;
    Object.defineProperties(this, {
      key: {
        enumerable: true,
        get() {
          return key;
        },
        set() {
          throw new TypeError("Cannot assign to read only property 'key' of object '#<R2MultipartUpload>'");
        }
      },
      uploadId: {
        enumerable: true,
        get() {
          return uploadId;
        },
        set() {
          throw new TypeError("Cannot assign to read only property 'uploadId' of object '#<R2MultipartUpload>'");
        }
      }
    });
  }
  #prepareCtx() {
    if (this.#blockGlobalAsyncIO)
      (0, import_shared2.assertInRequest)();
    const ctx = (0, import_shared2.getRequestContext)();
    ctx?.incrementInternalSubrequests();
    return ctx;
  }
  async #state() {
    const meta = await this.#storage.head(buildKey(this.key, this.uploadId));
    if (meta?.metadata === void 0) {
      return { exists: false, aborted: false, completed: false };
    }
    if ("aborted" in meta.metadata) {
      return { exists: false, aborted: true, completed: false };
    }
    if ("completed" in meta.metadata) {
      return { exists: false, aborted: false, completed: true };
    }
    return { exists: true, meta: meta.metadata };
  }
  async uploadPart(partNumber, value) {
    const ctx = this.#prepareCtx();
    if (arguments.length === 0) {
      throw new TypeError("Failed to execute 'uploadPart' on 'R2MultipartUpload': parameter 1 is not of type 'integer'.");
    }
    if (typeof partNumber !== "number") {
      partNumber = parseInt(String(partNumber));
    }
    if (isNaN(partNumber))
      partNumber = 0;
    let valueArray;
    if (typeof value === "string") {
      valueArray = encoder.encode(value);
    } else if (value instanceof ArrayBuffer) {
      valueArray = new Uint8Array(value);
    } else if (ArrayBuffer.isView(value)) {
      valueArray = (0, import_shared2.viewToArray)(value);
    } else if (value instanceof import_buffer.Blob) {
      valueArray = new Uint8Array(await value.arrayBuffer());
    } else if (value instanceof import_web2.ReadableStream) {
      if (!isKnownLengthStream(value)) {
        throw new TypeError("Provided readable stream must have a known length (request/response body or readable half of FixedLengthStream)");
      }
      valueArray = new Uint8Array(await (0, import_consumers2.arrayBuffer)(value));
    } else {
      throw new TypeError("Failed to execute 'uploadPart' on 'R2MultipartUpload': parameter 2 is not of type 'ReadableStream or ArrayBuffer or ArrayBufferView or string or Blob'.");
    }
    validatePartNumber(partNumber);
    validateMultipartKey("uploadPart", this.key);
    if (!(await this.#state()).exists) {
      throw new Error("uploadPart: The specified multipart upload does not exist. (10024)");
    }
    const partKey = buildKey(this.key, this.uploadId, partNumber);
    const etag = generateId();
    await this.#storage.put(partKey, {
      value: valueArray,
      metadata: {
        size: valueArray.byteLength,
        md5: createMD5Hash(valueArray),
        etag
      }
    });
    await (0, import_shared2.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
    return { partNumber, etag };
  }
  async abort() {
    const ctx = this.#prepareCtx();
    validateMultipartKey("abortMultipartUpload", this.key);
    const state = await this.#state();
    if (!state.exists) {
      if (state.aborted || state.completed) {
        await (0, import_shared2.waitForOpenInputGate)();
        ctx?.advanceCurrentTime();
        return;
      } else {
        throw new Error("abortMultipartUpload: We encountered an internal error. Please try again. (10001)");
      }
    }
    await deleteMultipartParts(this.#storage, this.key, this.uploadId);
    const indexKey = buildKey(this.key, this.uploadId);
    await this.#storage.put(indexKey, {
      value: new Uint8Array(),
      metadata: { aborted: true }
    });
    await (0, import_shared2.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
  }
  async complete(uploadedParts) {
    const ctx = this.#prepareCtx();
    if (!Array.isArray(uploadedParts)) {
      throw new TypeError("Failed to execute 'complete' on 'R2MultipartUpload': parameter 1 is not of type 'Array'.");
    }
    uploadedParts = uploadedParts.map((part, i) => {
      if (typeof part !== "object") {
        throw new TypeError(`Incorrect type for array element ${i}: the provided value is not of type 'UploadedPart'.`);
      }
      part = { partNumber: part.partNumber, etag: part.etag };
      if (typeof part.partNumber !== "number") {
        part.partNumber = parseInt(String(part.partNumber));
      }
      if (isNaN(part.partNumber))
        part.partNumber = 0;
      part.etag = String(part.etag);
      return part;
    });
    for (const part of uploadedParts) {
      validatePartNumber(part.partNumber);
    }
    validateMultipartKey("completeMultipartUpload", this.key);
    const state = await this.#state();
    if (!state.exists) {
      throw new Error(state.completed ? "completeMultipartUpload: The specified multipart upload does not exist. (10024)" : "completeMultipartUpload: We encountered an internal error. Please try again. (10001)");
    }
    const partNumberSet = new Set();
    for (const { partNumber } of uploadedParts) {
      if (partNumberSet.has(partNumber)) {
        throw new Error("completeMultipartUpload: We encountered an internal error. Please try again. (10001)");
      }
      partNumberSet.add(partNumber);
    }
    const partMetas = await Promise.all(uploadedParts.map(({ partNumber }) => {
      const partKey = buildKey(this.key, this.uploadId, partNumber);
      return this.#storage.head(partKey);
    }));
    const parts = partMetas.map((partMeta, i) => {
      const uploadedPart = uploadedParts[i];
      if (partMeta?.metadata === void 0 || partMeta.metadata.etag !== uploadedPart.etag) {
        throw new Error("completeMultipartUpload: One or more of the specified parts could not be found. (10025)");
      }
      return { ...uploadedPart, ...partMeta.metadata };
    });
    for (const part of parts.slice(0, -1)) {
      if (part.size < this.#minMultipartUploadSize) {
        throw new Error("completeMultipartUpload: Your proposed upload is smaller than the minimum allowed object size.");
      }
    }
    parts.sort((a, b) => a.partNumber - b.partNumber);
    let partSize;
    for (const part of parts.slice(0, -1)) {
      if (partSize === void 0)
        partSize = part.size;
      if (part.size < this.#minMultipartUploadSize || part.size !== partSize) {
        throw new Error("completeMultipartUpload: There was a problem with the multipart upload. (10048)");
      }
    }
    if (partSize !== void 0 && parts[parts.length - 1].size > partSize) {
      throw new Error("completeMultipartUpload: There was a problem with the multipart upload. (10048)");
    }
    const existingMeta = await this.#storage.head(this.key);
    const indexKey = buildKey(this.key, this.uploadId);
    const totalSize = parts.reduce((acc, { size }) => acc + size, 0);
    const etag = generateMultipartEtag(parts.map(({ md5 }) => md5));
    const metadata = {
      key: this.key,
      version: createVersion(),
      size: totalSize,
      etag,
      httpEtag: `"${etag}"`,
      uploaded: new Date(),
      httpMetadata: state.meta.httpMetadata,
      customMetadata: state.meta.customMetadata,
      checksums: {},
      multipart: {
        uploadId: this.uploadId,
        parts: parts.map(({ partNumber, size }) => ({ partNumber, size }))
      }
    };
    await (0, import_shared2.waitForOpenOutputGate)();
    await this.#storage.putMany([
      [this.key, { value: new Uint8Array(), metadata }],
      [indexKey, { value: new Uint8Array(), metadata: { completed: true } }]
    ]);
    await (0, import_shared2.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
    const used = new Set(parts.map(({ partNumber }) => buildKey(this.key, this.uploadId, partNumber)));
    await deleteMultipartParts(this.#storage, this.key, this.uploadId, used);
    if (existingMeta?.metadata?.multipart !== void 0) {
      await deleteMultipartParts(this.#storage, this.key, existingMeta.metadata.multipart.uploadId);
    }
    return new R2Object(metadata);
  }
};

// packages/r2/src/bucket.ts
var MAX_LIST_KEYS = 1e3;
var MAX_VALUE_SIZE = 5 * 1e3 * 1e3 * 1e3 - 5 * 1e3 * 1e3;
var UNPAIRED_SURROGATE_PAIR_REGEX = /^(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])$/;
var encoder2 = new import_util2.TextEncoder();
function throwR2Error(method, status, message) {
  throw new Error(`R2 ${method} failed: (${status}) ${message}`);
}
function validateKey(method, key) {
  const keyLength = encoder2.encode(key).byteLength;
  if (UNPAIRED_SURROGATE_PAIR_REGEX.test(key)) {
    throwR2Error(method, 400, "Key contains an illegal unicode value(s).");
  }
  if (keyLength >= MAX_KEY_SIZE) {
    throwR2Error(method, 414, `UTF-8 encoded length of ${keyLength} exceeds key length limit of ${MAX_KEY_SIZE}.`);
  }
  if (key.startsWith(_INTERNAL_PREFIX)) {
    throwR2Error(method, 400, `Key cannot start with "${_INTERNAL_PREFIX}".`);
  }
  return key;
}
function validateOnlyIf(onlyIf, method) {
  if (onlyIf instanceof import_undici2.Headers)
    return;
  if (typeof onlyIf !== "object") {
    throwR2Error(method, 400, "onlyIf must be an object, a Headers instance, or undefined.");
  }
  const { etagMatches, etagDoesNotMatch, uploadedBefore, uploadedAfter } = onlyIf;
  if (etagMatches !== void 0 && !(typeof etagMatches === "string" || Array.isArray(etagMatches))) {
    throwR2Error(method, 400, "etagMatches must be a string.");
  }
  if (etagDoesNotMatch !== void 0 && !(typeof etagDoesNotMatch === "string" || Array.isArray(etagDoesNotMatch))) {
    throwR2Error(method, 400, "etagDoesNotMatch must be a string.");
  }
  if (uploadedBefore !== void 0 && !(uploadedBefore instanceof Date)) {
    throwR2Error(method, 400, "uploadedBefore must be a Date.");
  }
  if (uploadedAfter !== void 0 && !(uploadedAfter instanceof Date)) {
    throwR2Error(method, 400, "uploadedAfter must be a Date.");
  }
}
function validateGetOptions(options) {
  const { onlyIf = {}, range = {} } = options;
  validateOnlyIf(onlyIf, "GET");
  if (typeof range !== "object") {
    throwR2Error("GET", 400, "range must either be an object or undefined.");
  }
  if (range instanceof import_undici2.Headers)
    return;
  const { offset, length, suffix } = range;
  if (offset !== void 0) {
    if (typeof offset !== "number") {
      throwR2Error("GET", 400, "offset must either be a number or undefined.");
    }
    if (offset < 0) {
      throwR2Error("GET", 400, "Invalid range. Starting offset must be greater than or equal to 0.");
    }
  }
  if (length !== void 0 && typeof length !== "number") {
    throwR2Error("GET", 400, "length must either be a number or undefined.");
  }
  if (suffix !== void 0 && typeof suffix !== "number") {
    throwR2Error("GET", 400, "suffix must either be a number or undefined.");
  }
}
function validateHttpMetadata(httpMetadata) {
  if (httpMetadata === void 0 || httpMetadata instanceof import_undici2.Headers)
    return;
  if (typeof httpMetadata !== "object") {
    throwR2Error("PUT", 400, "httpMetadata must be an object or undefined.");
  }
  for (const [key, value] of Object.entries(httpMetadata)) {
    if (key === "cacheExpiry") {
      if (!(value instanceof Date) && value !== void 0) {
        throwR2Error("PUT", 400, "cacheExpiry's value must be a Date or undefined.");
      }
    } else {
      if (typeof value !== "string" && value !== void 0) {
        throwR2Error("PUT", 400, `${key}'s value must be a string or undefined.`);
      }
    }
  }
}
function validatePutHash(options, alg) {
  const hash = options[alg.field];
  let buffer;
  if (hash === void 0) {
    return;
  } else if (hash instanceof ArrayBuffer) {
    buffer = Buffer.from(hash);
  } else if (ArrayBuffer.isView(hash)) {
    buffer = Buffer.from((0, import_shared3.viewToArray)(hash));
  } else if (typeof hash === "string") {
    const expectedHex = alg.expectedBytes * 2;
    if (hash.length !== expectedHex) {
      throw new TypeError(`${alg.name} is ${expectedHex} hex characters, not ${hash.length}`);
    }
    if (!HEX_REGEXP.test(hash)) {
      throw new TypeError(`Provided ${alg.name} wasn't a valid hex string`);
    }
    buffer = Buffer.from(hash, "hex");
  } else {
    throw new TypeError(`Incorrect type for the '${alg.field}' field on 'PutOptions': the provided value is not of type 'ArrayBuffer or ArrayBufferView or string'.`);
  }
  if (buffer.byteLength !== alg.expectedBytes) {
    throw new TypeError(`${alg.name} is ${alg.expectedBytes} bytes, not ${buffer.byteLength}`);
  }
  return { alg, hash: buffer };
}
function validatePutHashes(options) {
  let hash;
  for (const alg of R2_HASH_ALGORITHMS) {
    const validatedHash = validatePutHash(options, alg);
    if (validatedHash !== void 0) {
      if (hash !== void 0) {
        throw new TypeError("You cannot specify multiple hashing algorithms.");
      }
      hash = validatedHash;
    }
  }
  return hash;
}
function validatePutOptions(options) {
  const { onlyIf = {}, httpMetadata, customMetadata } = options;
  validateOnlyIf(onlyIf, "PUT");
  validateHttpMetadata(httpMetadata);
  if (customMetadata !== void 0) {
    if (typeof customMetadata !== "object") {
      throwR2Error("PUT", 400, "customMetadata must be an object or undefined.");
    }
    for (const value of Object.values(customMetadata)) {
      if (typeof value !== "string") {
        throwR2Error("PUT", 400, "customMetadata values must be strings.");
      }
    }
  }
  return validatePutHashes(options);
}
function validateListOptions(options) {
  const { limit, prefix, cursor, delimiter, startAfter, include } = options;
  if (limit !== void 0) {
    if (typeof limit !== "number") {
      throwR2Error("LIST", 400, "limit must be a number or undefined.");
    }
    if (limit < 1 || limit > MAX_LIST_KEYS) {
      throwR2Error("LIST", 400, `MaxKeys params must be positive integer <= 1000.`);
    }
  }
  if (prefix !== void 0 && typeof prefix !== "string") {
    throwR2Error("LIST", 400, "prefix must be a string or undefined.");
  }
  if (cursor !== void 0 && typeof cursor !== "string") {
    throwR2Error("LIST", 400, "cursor must be a string or undefined.");
  }
  if (delimiter !== void 0 && typeof delimiter !== "string") {
    throwR2Error("LIST", 400, "delimiter must be a string or undefined.");
  }
  if (startAfter !== void 0 && typeof startAfter !== "string") {
    throwR2Error("LIST", 400, "startAfter must be a string or undefined.");
  }
  if (include !== void 0) {
    if (!Array.isArray(include)) {
      throwR2Error("LIST", 400, "include must be an array or undefined.");
    }
    for (const value of include) {
      if (value !== "httpMetadata" && value !== "customMetadata") {
        throwR2Error("LIST", 400, "include values must be httpMetadata and/or customMetadata strings.");
      }
    }
  }
}
async function _valueToArray(value) {
  if (typeof value === "string") {
    return encoder2.encode(value);
  } else if (value instanceof import_web3.ReadableStream) {
    return new Uint8Array(await (0, import_consumers3.arrayBuffer)(value));
  } else if (value instanceof ArrayBuffer) {
    return new Uint8Array(value);
  } else if (ArrayBuffer.isView(value)) {
    return (0, import_shared3.viewToArray)(value);
  } else if (value === null) {
    return new Uint8Array();
  } else if (value instanceof import_buffer2.Blob) {
    return new Uint8Array(await value.arrayBuffer());
  } else {
    throw new TypeError("R2 put() accepts only nulls, strings, Blobs, ArrayBuffers, ArrayBufferViews, and ReadableStreams as values.");
  }
}
function rangeHeaderToR2Range(headers, size) {
  const rangeHeader = headers.get("Range");
  if (rangeHeader !== null) {
    const ranges = (0, import_core3.parseRanges)(rangeHeader, size);
    if (ranges?.length === 1) {
      const [start, end] = ranges[0];
      return { offset: start, length: end - start + 1 };
    }
  }
  return {};
}
function buildKeyTypeError(method) {
  return `Failed to execute '${method}' on 'R2Bucket': parameter 1 is not of type 'string'.`;
}
var R2Bucket = class {
  #storage;
  #blockGlobalAsyncIO;
  #listRespectInclude;
  #multipartOpts;
  constructor(storage, {
    blockGlobalAsyncIO = false,
    listRespectInclude = true,
    minMultipartUploadSize
  } = {}) {
    this.#storage = storage;
    this.#blockGlobalAsyncIO = blockGlobalAsyncIO;
    this.#listRespectInclude = listRespectInclude;
    this.#multipartOpts = {
      storage,
      blockGlobalAsyncIO,
      minMultipartUploadSize
    };
  }
  #prepareCtx() {
    if (this.#blockGlobalAsyncIO)
      (0, import_shared3.assertInRequest)();
    const ctx = (0, import_shared3.getRequestContext)();
    ctx?.incrementInternalSubrequests();
    return ctx;
  }
  async #head(key) {
    const stored = await this.#storage.head(key);
    if (stored?.metadata === void 0)
      return null;
    const { metadata } = stored;
    parseR2ObjectMetadata(metadata);
    return metadata;
  }
  async head(key) {
    const ctx = this.#prepareCtx();
    if (arguments.length === 0) {
      throw new TypeError(buildKeyTypeError("head"));
    }
    key = String(key);
    validateKey("HEAD", key);
    const meta = await this.#head(key);
    await (0, import_shared3.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
    return meta === null ? null : new R2Object(meta);
  }
  async get(key, options) {
    const ctx = this.#prepareCtx();
    options = options ?? {};
    let { range = {} } = options;
    if (arguments.length === 0) {
      throw new TypeError(buildKeyTypeError("get"));
    }
    key = String(key);
    validateKey("GET", key);
    validateGetOptions(options);
    const onlyIf = parseOnlyIf(options.onlyIf);
    const meta = await this.#head(key);
    if (meta === null) {
      await (0, import_shared3.waitForOpenInputGate)();
      ctx?.advanceCurrentTime();
      return null;
    }
    if (!testR2Conditional(onlyIf, meta)) {
      await (0, import_shared3.waitForOpenInputGate)();
      ctx?.advanceCurrentTime();
      return new R2Object(meta);
    }
    if (range instanceof import_undici2.Headers) {
      range = rangeHeaderToR2Range(range, meta.size);
    }
    let value;
    try {
      if (meta.size === 0) {
        value = new Uint8Array();
      } else if (meta.multipart !== void 0) {
        const parsedRange = (0, import_shared3.parseRange)(range, meta.size);
        value = getMultipartValue(this.#storage, key, meta.multipart, parsedRange);
        meta.range = parsedRange;
      } else {
        const stored = await this.#storage.getRange(key, range);
        if (stored === void 0)
          return null;
        value = stored.value;
        if ("range" in stored && stored.range !== void 0) {
          meta.range = stored.range;
        }
      }
    } catch {
      throwR2Error("GET", 400, "The requested range is not satisfiable.");
    }
    await (0, import_shared3.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
    return new R2ObjectBody(meta, value);
  }
  async put(key, value, options = {}) {
    const ctx = this.#prepareCtx();
    if (arguments.length === 0) {
      throw new TypeError(buildKeyTypeError("put"));
    }
    key = String(key);
    validateKey("PUT", key);
    const specifiedHash = validatePutOptions(options);
    const { customMetadata = {} } = options;
    let { onlyIf, httpMetadata } = options;
    onlyIf = parseOnlyIf(onlyIf);
    httpMetadata = parseHttpMetadata(httpMetadata);
    const meta = await this.#head(key) ?? void 0;
    if (!testR2Conditional(onlyIf, meta))
      return null;
    const toStore = await _valueToArray(value);
    if (toStore.byteLength > MAX_VALUE_SIZE) {
      throwR2Error("PUT", 400, `Value length of ${toStore.byteLength} exceeds limit of ${MAX_VALUE_SIZE}.`);
    }
    const checksums = {};
    if (specifiedHash !== void 0) {
      const computedHash = import_crypto3.default.createHash(specifiedHash.alg.field).update(toStore).digest();
      if (!specifiedHash.hash.equals(computedHash)) {
        throw new Error(`put: The ${specifiedHash.alg.name} checksum you specified did not match what we received.`);
      }
      checksums[specifiedHash.alg.field] = computedHash.toString("hex");
    }
    const md5Hash = createMD5Hash(toStore);
    const metadata = {
      key,
      size: toStore.byteLength,
      etag: md5Hash,
      version: createVersion(),
      httpEtag: `"${md5Hash}"`,
      uploaded: new Date(),
      httpMetadata,
      customMetadata,
      checksums
    };
    await (0, import_shared3.waitForOpenOutputGate)();
    await this.#storage.put(key, {
      value: toStore,
      metadata
    });
    if (meta?.multipart !== void 0) {
      await deleteMultipartParts(this.#storage, key, meta.multipart.uploadId);
    }
    await (0, import_shared3.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
    return new R2Object(metadata);
  }
  async delete(keys) {
    const ctx = this.#prepareCtx();
    if (arguments.length === 0) {
      throw new TypeError(buildKeyTypeError("delete"));
    }
    if (!Array.isArray(keys))
      keys = [keys];
    keys = keys.map((key) => validateKey("DELETE", String(key)));
    await (0, import_shared3.waitForOpenOutputGate)();
    const keyMetas = await Promise.all(keys.map((key) => this.#head(key)));
    await this.#storage.deleteMany(keys);
    const deletePartsPromises = keys.map((key, i) => {
      const keyMeta = keyMetas[i];
      if (keyMeta?.multipart !== void 0) {
        return deleteMultipartParts(this.#storage, key, keyMeta.multipart.uploadId);
      }
    });
    await Promise.all(deletePartsPromises);
    await (0, import_shared3.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
  }
  async list(listOptions = {}) {
    const ctx = this.#prepareCtx();
    const delimitedPrefixes = new Set();
    validateListOptions(listOptions);
    const { prefix = "", include = [], startAfter, cursor = "" } = listOptions;
    let { delimiter, limit = MAX_LIST_KEYS } = listOptions;
    if (delimiter === "")
      delimiter = void 0;
    if (include.length > 0)
      limit = Math.min(limit, 100);
    if (startAfter !== void 0)
      limit++;
    const res = await this.#storage.list({
      prefix,
      excludePrefix: _INTERNAL_PREFIX,
      limit,
      cursor,
      start: startAfter,
      delimiter
    });
    for (const dP of res.delimitedPrefixes ?? [])
      delimitedPrefixes.add(dP);
    const objects = res.keys.map((k) => k.metadata).filter((metadata) => metadata !== void 0).map((metadata) => {
      if (this.#listRespectInclude) {
        if (!include.includes("httpMetadata"))
          metadata.httpMetadata = {};
        if (!include.includes("customMetadata"))
          metadata.customMetadata = {};
      }
      parseR2ObjectMetadata(metadata);
      return new R2Object(metadata);
    });
    if (startAfter !== void 0) {
      if (objects[0].key === startAfter) {
        objects.splice(0, 1);
      } else if (objects.length > limit - 1) {
        objects.splice(0, limit - 1);
      }
    }
    await (0, import_shared3.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
    const cursorLength = res.cursor.length > 0;
    return {
      objects,
      truncated: cursorLength,
      cursor: cursorLength ? res.cursor : void 0,
      delimitedPrefixes: [...delimitedPrefixes]
    };
  }
  async createMultipartUpload(key, options = {}) {
    const ctx = this.#prepareCtx();
    if (arguments.length === 0) {
      throw new TypeError(buildKeyTypeError("createMultipartUpload"));
    }
    key = String(key);
    validateMultipartKey("createMultipartUpload", key);
    if (typeof options !== "object") {
      throw new TypeError("Failed to execute 'createMultipartUpload' on 'R2Bucket': parameter 2 is not of type 'MultipartOptions'.");
    }
    if (options.customMetadata !== void 0 && typeof options.customMetadata !== "object") {
      throw new TypeError("Incorrect type for the 'customMetadata' field on 'MultipartOptions': the provided value is not of type 'object'.");
    }
    if (options.httpMetadata !== void 0 && typeof options.httpMetadata !== "object") {
      throw new TypeError("Incorrect type for the 'httpMetadata' field on 'MultipartOptions': the provided value is not of type 'HttpMetadata or Headers'.");
    }
    const customMetadata = options.customMetadata ?? {};
    const httpMetadata = parseHttpMetadata(options.httpMetadata);
    const upload = await createMultipartUpload(key, { customMetadata, httpMetadata }, this.#multipartOpts);
    await (0, import_shared3.waitForOpenInputGate)();
    ctx?.advanceCurrentTime();
    return upload;
  }
  resumeMultipartUpload(key, uploadId) {
    if (arguments.length === 0) {
      throw new TypeError(buildKeyTypeError("resumeMultipartUpload"));
    }
    if (arguments.length === 1) {
      throw new TypeError("Failed to execute 'resumeMultipartUpload' on 'R2Bucket': parameter 2 is not of type 'string'.");
    }
    key = String(key);
    uploadId = String(uploadId);
    return new R2MultipartUpload(key, uploadId, this.#multipartOpts);
  }
};

// packages/r2/src/plugin.ts
var import_shared4 = __toModule(require("@miniflare/shared"));
var R2Plugin = class extends import_shared4.Plugin {
  r2Buckets;
  r2Persist;
  #persist;
  constructor(ctx, options) {
    super(ctx);
    this.assignOptions(options);
    this.#persist = (0, import_shared4.resolveStoragePersist)(ctx.rootPath, this.r2Persist);
  }
  getBucket(storage, bucket, blockGlobalAsyncIO = false) {
    return new R2Bucket(storage.storage(bucket, this.#persist), {
      blockGlobalAsyncIO,
      listRespectInclude: this.ctx.compat.isEnabled("r2_list_honor_include")
    });
  }
  setup(storageFactory) {
    const blockGlobalAsyncIO = !this.ctx.globalAsyncIO;
    const bindings = {};
    for (const bucket of this.r2Buckets ?? []) {
      bindings[bucket] = this.getBucket(storageFactory, bucket, blockGlobalAsyncIO);
    }
    return { bindings };
  }
};
__decorateClass([
  (0, import_shared4.Option)({
    type: import_shared4.OptionType.ARRAY,
    name: "r2",
    alias: "r",
    description: "R2 bucket to bind",
    logName: "R2 Buckets",
    fromWrangler: ({ r2_buckets }) => r2_buckets?.map(({ binding }) => binding)
  })
], R2Plugin.prototype, "r2Buckets", 2);
__decorateClass([
  (0, import_shared4.Option)({
    type: import_shared4.OptionType.BOOLEAN_STRING,
    description: "Persist R2 data (to optional path)",
    logName: "R2 Persistence",
    fromWrangler: ({ miniflare }) => miniflare?.r2_persist
  })
], R2Plugin.prototype, "r2Persist", 2);
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  Checksums,
  HEX_REGEXP,
  MAX_KEY_SIZE,
  R2Bucket,
  R2MultipartUpload,
  R2Object,
  R2ObjectBody,
  R2Plugin,
  R2_HASH_ALGORITHMS,
  _INTERNAL_PREFIX,
  _valueToArray,
  createMD5Hash,
  createMultipartUpload,
  createVersion,
  deleteMultipartParts,
  getMultipartValue,
  parseHttpMetadata,
  parseOnlyIf,
  parseR2ObjectMetadata,
  testR2Conditional,
  validateMultipartKey
});
//# sourceMappingURL=index.js.map
